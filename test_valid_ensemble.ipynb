{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skorch import NeuralNetClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './MURA-v1.1/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_image_paths_csv = \"valid_image_paths.csv\"\n",
    "df_valid_data_paths = pd.read_csv(os.path.join(path,valid_image_paths_csv),dtype=str,header=None)\n",
    "df_valid_data_paths.columns = ['image_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_data_paths['label'] = df_valid_data_paths['image_path'].map(lambda x:'positive' if 'positive' in x else 'negative')\n",
    "df_valid_data_paths['category']  = df_valid_data_paths['image_path'].apply(lambda x: x.split('/')[2])\n",
    "#df_valid_data_paths['dir'] =  df_valid_data_paths['image_path'].apply(lambda x: x.split('/')[1])\n",
    "#df_valid_data_paths['patientId']  = df_valid_data_paths['image_path'].apply(lambda x: x.split('/')[3].replace('patient',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_data_paths[\"label\"] = df_valid_data_paths[\"label\"].replace({'positive': 1, 'negative': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import butterworth\n",
    "from skimage.filters import gaussian\n",
    "from skimage import exposure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.color import rgb2gray\n",
    "class MuraDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None, device='cpu'):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.item()\n",
    "        \n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path)\n",
    "        image = image.convert('RGB')\n",
    "        \n",
    "        # Convert PIL Image to numpy array\n",
    "        image_np = np.array(image)\n",
    "        \n",
    "        image_gray = rgb2gray(image_np)\n",
    "        \n",
    "        # Apply adaptive histogram equalization\n",
    "        image_gray = exposure.equalize_adapthist(image_gray, clip_limit=0.02)\n",
    "\n",
    "        \n",
    "        # Apply Butterworth filter\n",
    "        image_butterworth = butterworth(image_gray)\n",
    "\n",
    "        \n",
    "        # Apply Gaussian filter\n",
    "        image_gaussian = gaussian(image_gray)\n",
    "        \n",
    "        # Combine the two images into one (stack them along the last axis)\n",
    "        # Create a 3 channel image from the butterworth and gaussian filtered images\n",
    "        image_combined = np.stack([image_butterworth, image_gaussian, image_gray], axis=-1)\n",
    "        \n",
    "        image_combined = (image_combined - np.min(image_combined)) / (np.max(image_combined) - np.min(image_combined))\n",
    "        \n",
    "        # Convert to 8-bit image for PIL\n",
    "        image_combined = img_as_ubyte(image_combined)\n",
    "        \n",
    "        # Convert numpy array back to PIL Image\n",
    "        image = Image.fromarray(image_combined)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        image = image.to(self.device)\n",
    "        \n",
    "        label = torch.tensor(label).to(self.device)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hamad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\Hamad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\Hamad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "batchsize = 12\n",
    "\n",
    "\n",
    "val_transform = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "Mura_transform_valid = MuraDataset(df_valid_data_paths[\"image_path\"], df_valid_data_paths[\"label\"], transform=val_transform,device='cuda')\n",
    "valid_loader = DataLoader(Mura_transform_valid, batch_size=batchsize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "googleNet = torch.load('Models weights\\googlenet_mura_phase_3_20epoch.pth')\n",
    "swin = torch.load('Models weights\\SWIN_mura_phase_3_v2_7epoch.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [100/267] Processed\n",
      "Test Batch [200/267] Processed\n",
      "Test Accuracy: 0.8073\n",
      "Test Precision: 0.8144\n",
      "Test Recall: 0.8073\n",
      "Test F1-Score: 0.8053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Switch the model to evaluation mode\n",
    "googleNet.eval()\n",
    "swin.eval()\n",
    "\n",
    "# Initialize lists to store all true labels and all predictions\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "# Disabling gradient calculation\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(valid_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass for both models\n",
    "        outputs_googleNet = googleNet(images)\n",
    "        outputs_swin = swin(images)\n",
    "        logits = outputs_swin.logits \n",
    "        # Apply softmax to get probabilities from logits\n",
    "        probs_googleNet = F.softmax(outputs_googleNet, dim=1)\n",
    "        probs_swin = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Change it to numpy because of some objects issues\n",
    "        swin_proba_np = probs_swin.cpu().numpy()\n",
    "        googleNet_proba_np = probs_googleNet.cpu().numpy()\n",
    "\n",
    "        # Soft Voting: Average the probabilities\n",
    "        averaged_probs = (googleNet_proba_np + swin_proba_np) / 2\n",
    "\n",
    "        \n",
    "        predicted = np.argmax(averaged_probs, axis=1)  # This will give you the indices of the maximum values along axis 1\n",
    "\n",
    "\n",
    "        # Store predictions and true labels for later calculation of metrics\n",
    "        # Store predictions and true labels for later calculation of metrics\n",
    "        all_predictions.extend(predicted.tolist())  # converted to a list before extending\n",
    "        all_labels.extend(labels.cpu().numpy().tolist())  # converted to a list before extending\n",
    "\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Test Batch [{batch_idx+1}/{len(valid_loader)}] Processed\")\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Accuracy: 0.8073\n",
    "# Test Precision: 0.8144\n",
    "# Test Recall: 0.8073\n",
    "# Test F1-Score: 0.8053"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
