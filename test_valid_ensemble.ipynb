{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './MURA-v1.1/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_image_paths_csv = \"valid_image_paths.csv\"\n",
    "df_valid_data_paths = pd.read_csv(os.path.join(path,valid_image_paths_csv),dtype=str,header=None)\n",
    "df_valid_data_paths.columns = ['image_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_data_paths['label'] = df_valid_data_paths['image_path'].map(lambda x:'positive' if 'positive' in x else 'negative')\n",
    "df_valid_data_paths['category']  = df_valid_data_paths['image_path'].apply(lambda x: x.split('/')[2])\n",
    "#df_valid_data_paths['dir'] =  df_valid_data_paths['image_path'].apply(lambda x: x.split('/')[1])\n",
    "#df_valid_data_paths['patientId']  = df_valid_data_paths['image_path'].apply(lambda x: x.split('/')[3].replace('patient',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_data_paths[\"label\"] = df_valid_data_paths[\"label\"].replace({'positive': 1, 'negative': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import butterworth\n",
    "from skimage.filters import gaussian\n",
    "from skimage import exposure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.color import rgb2gray\n",
    "class MuraDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None, device='cpu'):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.item()\n",
    "        \n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path)\n",
    "        image = image.convert('RGB')\n",
    "        \n",
    "        # Convert PIL Image to numpy array\n",
    "        image_np = np.array(image)\n",
    "        \n",
    "        image_gray = rgb2gray(image_np)\n",
    "        \n",
    "        # Apply adaptive histogram equalization\n",
    "        image_gray = exposure.equalize_adapthist(image_gray, clip_limit=0.02)\n",
    "\n",
    "        \n",
    "        # Apply Butterworth filter\n",
    "        image_butterworth = butterworth(image_gray)\n",
    "\n",
    "        \n",
    "        # Apply Gaussian filter\n",
    "        image_gaussian = gaussian(image_gray)\n",
    "        \n",
    "        # Combine the two images into one (stack them along the last axis)\n",
    "        # Create a 3 channel image from the butterworth and gaussian filtered images\n",
    "        image_combined = np.stack([image_butterworth, image_gaussian, image_gray], axis=-1)\n",
    "        \n",
    "        image_combined = (image_combined - np.min(image_combined)) / (np.max(image_combined) - np.min(image_combined))\n",
    "        \n",
    "        # Convert to 8-bit image for PIL\n",
    "        image_combined = img_as_ubyte(image_combined)\n",
    "        \n",
    "        # Convert numpy array back to PIL Image\n",
    "        image = Image.fromarray(image_combined)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        image = image.to(self.device)\n",
    "        \n",
    "        label = torch.tensor(label).to(self.device)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "batchsize = 16\n",
    "mean_values = [0.2665, 0.4648, 0.4648]# Calculated\n",
    "std_values = [0.1079, 0.1650, 0.1666] # Calculated\n",
    "\n",
    "val_transform = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(mean=mean_values, std=std_values)\n",
    "\n",
    "])\n",
    "\n",
    "Mura_transform_valid = MuraDataset(df_valid_data_paths[\"image_path\"], df_valid_data_paths[\"label\"], transform=val_transform,device='cuda')\n",
    "valid_loader = DataLoader(Mura_transform_valid, batch_size=batchsize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#googleNet = torch.load('Models weights\\googlenet_mura_Norma_p2LionOPT_40epoch.pth')\n",
    "googleNet = torch.load('Models weights\\googlenet_mura_Norma_p2LionOPT_40epoch.pth')\n",
    "swin = torch.load('SWIN_PART3mura_LION_Normalization_Balanced20epoch.pth')\n",
    "densenet = torch.load('Models weights\\densenet_mura_phase_3_p2_20epoch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [100/200] Processed\n",
      "Test Batch [200/200] Processed\n",
      "Test Accuracy: 0.8180\n",
      "Test Precision: 0.8205\n",
      "Test Recall: 0.8180\n",
      "Test F1-Score: 0.8171\n",
      "Test AUC: 0.8716\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Switch the model to evaluation mode\n",
    "googleNet.eval()\n",
    "swin.eval()\n",
    "#densenet.eval()\n",
    "\n",
    "# Initialize lists to store all true labels and all predictions\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "all_probabilities = []\n",
    "\n",
    "# Disabling gradient calculation\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(valid_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass for all three models\n",
    "        outputs_googleNet = googleNet(images)\n",
    "        outputs_swin = swin(images)\n",
    "        #outputs_densenet = densenet(images)\n",
    "        logits = outputs_swin.logits \n",
    "        # Apply softmax to get probabilities from logits\n",
    "        probs_googleNet = F.softmax(outputs_googleNet, dim=1)\n",
    "        #probs_densenet = F.softmax(outputs_densenet,dim=1)\n",
    "        probs_swin = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Change it to numpy because of some objects issues\n",
    "        swin_proba_np = probs_swin.cpu().numpy()\n",
    "        googleNet_proba_np = probs_googleNet.cpu().numpy()\n",
    "        #densenet_proba_np = probs_densenet.cpu().numpy()\n",
    "\n",
    "        # Soft Voting: Average the probabilities\n",
    "        averaged_probs = (googleNet_proba_np + swin_proba_np) / 2\n",
    "\n",
    "        \n",
    "        predicted = np.argmax(averaged_probs, axis=1)  # This will give you the indices of the maximum values along axis 1\n",
    "\n",
    "\n",
    "        # Store predictions and true labels for later calculation of metrics\n",
    "        all_predictions.extend(predicted.tolist())  # converted to a list before extending\n",
    "        all_labels.extend(labels.cpu().numpy().tolist())  # converted to a list before extending\n",
    "        all_probabilities.extend(averaged_probs.tolist())\n",
    "\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Test Batch [{batch_idx+1}/{len(valid_loader)}] Processed\")\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "# change this to all_predictions or predicted\n",
    "auc = roc_auc_score(all_labels, [proba[1] for proba in all_probabilities])\n",
    "\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1-Score: {f1:.4f}\")\n",
    "print(f\"Test AUC: {auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Accuracy: 0.8120\n",
    "# Test Precision: 0.8215\n",
    "# Test Recall: 0.8120\n",
    "# Test F1-Score: 0.8097"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
